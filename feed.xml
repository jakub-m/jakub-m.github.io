<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://jakub-m.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://jakub-m.github.io/" rel="alternate" type="text/html" /><updated>2022-09-10T23:32:48+02:00</updated><id>https://jakub-m.github.io/feed.xml</id><title type="html">Jakub Mikians blog</title><subtitle>An exercise in writing. All the opinions are mine, unless you share them.</subtitle><entry><title type="html">User settings, Lamport clocks and lightweight formal methods</title><link href="https://jakub-m.github.io/2022/07/17/laport-clocks-formal.html" rel="alternate" type="text/html" title="User settings, Lamport clocks and lightweight formal methods" /><published>2022-07-17T23:46:39+02:00</published><updated>2022-07-17T23:46:39+02:00</updated><id>https://jakub-m.github.io/2022/07/17/laport-clocks-formal</id><content type="html" xml:base="https://jakub-m.github.io/2022/07/17/laport-clocks-formal.html"><![CDATA[<p>Synchronizing settings between browsers and a backend seems a simple task. It turns out that it can teach us some
lessons on distributes systems and formal modeling.  After you read this post, you will learn, I hope, how we used
<a href="https://martinfowler.com/articles/patterns-of-distributed-systems/lamport-clock.html">Lamport Clocks</a> to synchronize user settings between browsers and backend service. You will also learn
how we used <a href="https://dl.acm.org/doi/10.1145/3477132.3483540">Lightweight Formal Methods</a> to find bugs in our implementation of the synchronization
protocol.</p>

<p>At <a href="https://www.airspace-intelligence.com/company">Airspace Intelligence</a> we work on products supporting airlines’ operations. One of the products we are
building is an application for messaging between the dispatchers (the ground staff coordinating the carriers’
aircrafts), and the pilots (the folks driving the planes). Think of WhatsApp for airplanes.</p>

<p>The application, or just the App, integrates with the <a href="https://en.wikipedia.org/wiki/ACARS">existing airline’s systems</a>.  The App delivers slick
browser UI, and at the same time needs to communicate with the existing notification systems to notify that the
dispatcher has a new message from the pilot. The “existing notification systems” are not browser-based, so even though
the messaging itself happens in the browser, the notification flow happens outside of the browser. Think of
push notifications that are delivered to a device outside browser. To deliver messages to proper users (e.g. all the
dispatchers interested in flights departing from Seattle), the backend service relies on the user settings to figure
out which user (dispatcher) should be notified about which message. Different dispatchers handle a different set of flights.</p>

<p>It is important that the browsers serving the App, connected to the backend, and the backend itself, have a consistent
view on the user settings,  so the backend can reliably trigger send notifications to the dispatchers about pending
messages. The case we especially want to avoid is that the browsers “see” different settings than the backed, or that
the settings between the browsers and the backend don’t converge. At the same time, we want to provide a snappy
experience, when the dispatcher can select different settings (different flight selectors), and the settings won’t
flicker as the requests and responses go back and forth between the browser and the backend.</p>

<h1 id="but-thats-trivial-right">But that’s trivial, right?</h1>

<p>Superficially yes. But if you want to be <em>sure</em> that the settings are synchronized correctly, avoid weird edge cases
and still provide a snappy experience, you need to take extra care.</p>

<p>With two browsers and a single backend (single storage), different things can happen. A user can click settings in one
browser, and then different settings in another one. There can be transient network problems so the browsers fail to
send the up-to-date settings to the backend. The user can click back and forth the settings several times, or restart the
browser.</p>

<p>The simplest thing to do would be to send the settings with each click. The problem is that if you clicked different
settings fast, or when the network is slow, it could happen that you changed some setting A and then a different
settings B, but after you clicked B your browser received a response from the backend for “A” change. The “A response”
would overwrite the “B” change in the browser, causing the settings to flicker. Alternatively, you could wait for a response
after each request, but then the experience wouldn’t be “snappy”.</p>

<p>Also, what if your request never reached the backend service?  Aha, you say, let’s add a periodic sync job in the
browser to synchronize the state of the browser with the backend. This would also protect us from the case when someone
changed settings in a different browser window. This would work, but you need to figure which settings are the “current”
ones, the ones in the browser or the ones on the backend. Easy, just add a clock. But now how can you be <em>sure</em> that the
clock is right? It should, <a href="https://phys.org/news/2012-07-wreaks-internet-havoc.html">but what if not</a>? How can you reliably <a href="https://sookocheff.com/post/time/lamport-clock/">compare the clocks</a>?
Folk wisdom says to never trust external clocks.</p>

<p>You could add some integer that you increment every time you synchronize or change state, and choose the larger one…
Wait, sounds like you are inventing the…</p>

<h1 id="lamport-clocks">Lamport Clocks</h1>

<p>The idea is straightforward: make each process measure its own time, and synchronize the time when the processes
(browsers and the backend) exchange events.</p>

<p>Events make the time “tick”. When an event, like a change in the settings, happens, a process increments its local time
(an integer). When the processes exchange the information, they pass the counter along, compare the received counter
with the local counter, choose the larger one (local or received) together with the accompanying state (i.e. the
settings), <em>and increment the local clock by 1</em>. Mr. Lamport showed that such clocks allow reasoning about the <a href="https://en.wikipedia.org/wiki/Lamport_timestamp">ordering
of the events</a>.</p>

<p>Each time the user clicks the settings, the Lamport clock (a local integer) in the browser increments by 1. The settings
are sent from the browsers to the backend, and the “larger clock wins”. Eventually, all the browsers and the backend
should converge to the same values… At least that’s what we thought.</p>

<h1 id="lightweight-formal-methods">Lightweight formal methods</h1>

<p>Testing a distributed system, even as simple as the above, is difficult. There are <a href="https://en.wikipedia.org/wiki/TLA%2B">dedicated frameworks and languages,
like TLA+</a> for that purpose. While expressive and battle-proven, a “test”, or specification, written in
TLA+ would be doomed to become instantly unmaintained.  Instead, we adopted “Property-based testing” described in the
<a href="https://dl.acm.org/doi/10.1145/3477132.3483540">Lightweight Formal Methods</a> paper.  In a nutshell, the idea is that you implement simple reference
models, then randomly generate sets of events, and check if after running the events on the reference models the
properties of the system hold. Such “lightweight formal tests” are a part of the regular unit-test suite, together with
the other tests.</p>

<p>In our case, a “reference model” for a browser app was merely a class with two fields - “settings” and “Lamport clock”.
The backend service used in the tests was the <em>actual</em> backend service running locally as a part of the unit test setup.</p>

<p>The events generated were:</p>

<ol>
  <li>The user changed settings in the app and the app sent the up-to-date settings to the backend.</li>
  <li>The user changed settings but the browser did not send the up-to-date settings to the backend (e.g. because of
the connectivity issues).</li>
  <li>The browser synchronizes with the backend.</li>
  <li>The browser resets.</li>
</ol>

<p>What we tested for was the property: after a random set of events and two synchronization rounds between the browsers
and the backend, all the browsers and the backend had the same settings. We used “two synchronization rounds” as it
turned out that one synchronization round is not enough for convergence.</p>

<h1 id="the-bug">The bug</h1>

<p>So we run the test with thousands and thousands of sequences of events, and, to our surprise, the tests failed! There
was a sequence of events that caused the system to not converge to a single state. It turned out that 
the state would not converge when all of the browsers and the backend had different settings but the same values of Lamport
clocks. Consider the following sequence:</p>

<ol>
  <li>Initial state.
    <ul>
      <li>browser: settings: none, clock: 0</li>
      <li>backend: settings: none, clock: 0</li>
    </ul>
  </li>
  <li>The user changes settings in the browser, and the browser synchronizes the settings with the backend. The clock for
browser is 3: just after the settings change, locally the clock increments to 1, is sent to the backend, the backend
increments the clock to 2, and sends it to the browser where it is yet again incremented to 3.
    <ul>
      <li>browser: settings: foo, clock: 3</li>
      <li>backend: settings: foo, clock: 2</li>
    </ul>
  </li>
  <li>The browser resets, all the state is dropped.
    <ul>
      <li>browser: settings: none, clock: 0</li>
      <li>backend: settings: foo, clock: 2</li>
    </ul>
  </li>
  <li>The user changes the settings twice, but this time the state is not propagated to the backend (e.g. due to network
hiccups).
    <ul>
      <li>browser: settings: none, clock: 2</li>
      <li>backend: settings: foo, clock: 2</li>
    </ul>
  </li>
</ol>

<p>Now, if left like that, the state would never converge between the browser and the backend. Both ends have the same clock
value and cannot decide on the order of the events. Rare? Yes, rare. Correct? Definitely not!</p>

<p>The fix was to break the tie by incrementing the clock on the backend side whenever comes a request with the equal clock.
Intuitively, one can argue that something might have happened on the backend side meanwhile, e.g. settings changed to
some value and changed back to the original value, leaving the settings unchanged but the clock incremented. With the
above example, when the backend received an event with the browser clock value equal to the backend’s local clock value,
the backend would silently increment its clock and return it to the browser:</p>

<ol start="5">
  <li>Backend increments its clock on an equal input clock.
    <ul>
      <li>browser: settings: none, clock: 4</li>
      <li>backend: settings: foo, clock: 3</li>
    </ul>
  </li>
</ol>

<p>After the change, the test didn’t fail anymore.</p>

<h1 id="conclusions">Conclusions</h1>

<p>Handling even a simple distributed state is not trivial if one wants to do it correctly. Fortunately, algorithms and rich
research exist. Lightweight formal testing is a very <em>practical</em> framework for testing such algorithms in the
application context.</p>

<p>(<a href="https://news.ycombinator.com/item?id=32171619">on HN</a>)</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Synchronizing settings between browsers and a backend seems a simple task. It turns out that it can teach us some lessons on distributes systems and formal modeling. After you read this post, you will learn, I hope, how we used Lamport Clocks to synchronize user settings between browsers and backend service. You will also learn how we used Lightweight Formal Methods to find bugs in our implementation of the synchronization protocol.]]></summary></entry><entry><title type="html">Running Docker images without Docker</title><link href="https://jakub-m.github.io/2022/07/10/docker.html" rel="alternate" type="text/html" title="Running Docker images without Docker" /><published>2022-07-10T02:00:00+02:00</published><updated>2022-07-10T02:00:00+02:00</updated><id>https://jakub-m.github.io/2022/07/10/docker</id><content type="html" xml:base="https://jakub-m.github.io/2022/07/10/docker.html"><![CDATA[<p>I wrote this post trying to learn how <a href="https://en.wikipedia.org/wiki/Docker_(software)">Docker</a> works under the hood. My learning goal was to run a Docker image without Docker.</p>

<p>tl;dr: Surprisingly, Docker is not magic. Docker uses Linux cgroups, namespaces, overlayfs and other Linux mechanisms. Below I try to use those mechanisms by hand.</p>

<p>To reproduce the learning steps, clone <a href="https://github.com/jakub-m/no-docker">no-docker git repo</a> and follow the post and run the scripts.  I used Debian run from VirtualBox. Start with running <a href="https://github.com/jakub-m/no-docker/blob/main/00-prepare.sh">00-prepare.sh</a> to install all the dependencies and build a small <a href="https://github.com/jakub-m/no-docker/blob/main/tool.go"><code class="language-plaintext highlighter-rouge">tool</code> in Go</a> that we will use for experimenting.</p>

<p><a href="https://github.com/jakub-m/no-docker/blob/main/00-prepare.sh">00-prepare.sh</a></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#!/bin/bash
set -eux
sudo apt-get install -y git golang jq curl psmisc
curl -O https://raw.githubusercontent.com/moby/moby/master/contrib/download-frozen-image-v2.sh
chmod a+x download-frozen-image-v2.sh
go build -o tool tool.go
</code></pre></div></div>

<h1 id="docker-image">Docker image</h1>

<p>Let’s download and un-archive <a href="https://hub.docker.com/_/busybox">busybox image</a> by running <a href="https://github.com/jakub-m/no-docker/blob/main/10-busybox-image.sh">10-busybox-image.sh</a>.  You can see that a Docker image is just a nested tar archive:</p>

<p><a href="https://github.com/jakub-m/no-docker/blob/main/10-busybox-image.sh">10-busybox-image.sh</a></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#!/bin/bash

set -eux
set -o pipefail

./download-frozen-image-v2.sh ./image-busybox/ busybox:latest
mkdir -p image-busybox-layer
find image-busybox -name layer.tar | xargs -n1 tar -C image-busybox-layer -xf
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ tree image-busybox
image-busybox
|-- a01835d83d8f65e3722493f08f053490451c39bf69ab477b50777b059579198f.json
|-- b906f5815465b0f9bf3760245ce063df516c5e8c99cdd9fdc4ee981a06842872
|   |-- json
|   |-- layer.tar
|   `-- VERSION
|-- manifest.json
`-- repositories
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">layer.tar</code> is a file tree with busybox tooling:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>image-busybox-layer/
|-- bin
(...)
|   |-- less
|   |-- link
|   |-- linux32
|   |-- linux64
|   |-- linuxrc
|   |-- ln
(...)
|-- etc
|   |-- group
(...)
</code></pre></div></div>

<h1 id="namespace-magic">namespace magic</h1>

<p><a href="https://man7.org/linux/man-pages/man7/namespaces.7.html">Linux namespaces</a> create a separate “view” on Linux resources, such that one process can see the resources differently than other resources. The resources can be PIDs, file system mount points, network stack, and others.  You can see all the current namespaces with <code class="language-plaintext highlighter-rouge">lsns</code>. Let’s see how isolating and nesting PIDs look in practice with PID <a href="https://en.wikipedia.org/wiki/Linux_namespaces#Process_ID_(pid)">namespace</a>.</p>

<p><a href="https://man7.org/linux/man-pages/man1/unshare.1.html">unshare</a> system call and a command allows to set the separate namespace for a process. Run <a href="https://github.com/jakub-m/no-docker/blob/main/20-unshare.sh">20-unshare.sh</a> to fork a shell from busybox with a separate PID namespace, with a separate file system root.</p>

<p><a href="https://github.com/jakub-m/no-docker/blob/main/20-unshare.sh">20-unshare.sh</a></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#!/bin/bash

set -eux

cd image-busybox-layer
mkdir -p proc

sudo unshare --mount-proc \
    --fork \
    --pid \
    --cgroup \
    --root=$PWD \
    bin/sh
</code></pre></div></div>

<p>Have a look around. You will see that the root directory of the forked process is restricted (“jailed”) to the directory we specified when forking the shell. Now run the <code class="language-plaintext highlighter-rouge">tool</code> and see how the same process looks from the “inside” and “outside” of the forked shell. First copy the tool to XXX, then run the tool from the forked shell:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Run from the forked shell.  It does nothing but sleep.

./tool -hang hello &amp;
</code></pre></div></div>

<p>Restricting a directory tree of a process to a subdirectory is done with <a href="https://man7.org/linux/man-pages/man1/chroot.1.html">chroot</a>. You can check the actual root directory by checking /proc/*/root of processes:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Run this from the parent (outside) shell

dev@debian:~/no-docker$ find  /proc/$(pidof tool) -name root -type l 2&gt;/dev/null | sudo xargs -n1 ls -l
lrwxrwxrwx 1 root root 0 Aug 27 22:03 /proc/1985/task/1985/root -&gt; /home/dev/no-docker/image-busybox-layer
(...)
</code></pre></div></div>

<p>You can also see how the PID namespaces work. The <code class="language-plaintext highlighter-rouge">tool</code> in the parent shell and in the forked shell have separate PID numbers. Also, the parent shell sees the processes run in the forked shell, but not vice-versa.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># from the forked shell
/ # ps aux | grep '[t]ool'
    7 root      0:00 ./tool -hang hello
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># from the parent shell
dev@debian:~$ ps aux | grep '[t]ool'
root       464  0.0  0.2 795136  2724 pts/1    Sl   10:16   0:00 ./tool -hang hello
</code></pre></div></div>

<h1 id="cgroups-limiting-resources">cgroups, limiting resources</h1>

<p>While namespaces isolate resources, <a href="https://docs.kernel.org/admin-guide/cgroup-v2.html">cgroups (control groups)</a> put limits on those resources. You can find the control group of our hanging tool with the following, run from the parent shell:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dev@debian:~$ cat /proc/$(pidof tool)/cgroup
0::/user.slice/user-1000.slice/session-92.scope
</code></pre></div></div>

<p>Let’s now use cgroups to see how we can cap memory of the forked shell.</p>

<p>First, run the tool with -mb option to make it allocate n MBs of memory:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># kill the previous tool if it still runs
killall -9 tool
./tool -mb 200
</code></pre></div></div>

<p>Find the file controlling the maximum memory of the tool process:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>find /sys/fs/cgroup/ | grep $( cat /proc/$(pidof tool)/cgroup | cut -d/ -f 2-) | grep memory.max
/sys/fs/cgroup/user.slice/user-1000.slice/session-92.scope/memory.max
</code></pre></div></div>

<p>“/sys/fs/cgroup” is a mount point for cgroups file system:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mount | grep cgroup
cgroup2 on /sys/fs/cgroup type cgroup2 (rw,nosuid,nodev,noexec,relatime,nsdelegate,memory_recursiveprot)
</code></pre></div></div>

<p><a href="https://facebookmicrosites.github.io/cgroup2/docs/memory-controller.html">“memory.max”</a> is a memory hard limit in the memory controller. Passing the hard limit causes OOM when memory usage cannot be reduced (more about it in a while).</p>

<p>Let’s put 100MB limit:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo sh -c 'echo 100m &gt; /sys/fs/cgroup/user.slice/user-1000.slice/session-92.scope/memory.max'
</code></pre></div></div>

<p>You will notice that the tool process… was not killed. How come? if you inspect <a href="https://facebookmicrosites.github.io/cgroup2/docs/memory-controller.html">memory.events</a> file, you will see that “max” entry increments.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat /sys/fs/cgroup/user.slice/user-1000.slice/session-92.scope/memory.events

low 0
high 0
max 3534 &lt;&lt; this changes when you run over the max limit
oom 0
oom_kill 0
</code></pre></div></div>

<p>The process was not killed because OS swapped the excessive memory. Check <code class="language-plaintext highlighter-rouge">cat /proc/swaps</code>, print it several times to see how it changes:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dev@debian:~/no-docker$ while [ 1 ]; do cat /proc/swaps; sleep 2; done
Filename				Type		Size		Used		Priority
/dev/sda5                               partition	998396		2372		-2
Filename				Type		Size		Used		Priority
/dev/sda5                               partition	998396		2372		-2

# here I run the tool, you can see how the memory is swapped

Filename				Type		Size		Used		Priority
/dev/sda5                               partition	998396		103860		-2
Filename				Type		Size		Used		Priority
/dev/sda5                               partition	998396		121540		-2
Filename				Type		Size		Used		Priority
/dev/sda5                               partition	998396		116604		-2
</code></pre></div></div>

<p>If you turn the swapping off with <a href="https://linux.die.net/man/8/swapoff">swapoff</a>, the tool will be OOM-killed.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo swapoff -a
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2022/09/10 06:32:38 heap 0 mb, sys 218 mb
2022/09/10 06:32:39 allocate 200MB of memory
Killed
</code></pre></div></div>

<h1 id="overlayfs">overlayfs</h1>

<p>The last thing I looked at is the overlay file system, underlying volumes in Docker.  The <a href="https://www.kernel.org/doc/html/latest/filesystems/overlayfs.html">overlay file system</a> allows logically merging of different mount points. You can overlay part of a parent file system with the forked file system.  You can check the overlayfs with the following:</p>

<p><a href="https://github.com/jakub-m/no-docker/blob/main/40-overlayfs.sh">40-overlayfs.sh</a></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#!/bin/bash

set -eux  

sudo mkdir -p /upper /lower /work /merged
sudo chmod 777 /upper /lower /work /merged
echo 'upper foo' &gt; /upper/foo
echo 'upper bar' &gt; /upper/bar
echo 'lower bar' &gt; /lower/bar
echo 'lower quux' &gt; /lower/quux
sudo mount -t overlay overlay -olowerdir=/lower,upperdir=/upper,workdir=/work /merged 
</code></pre></div></div>

<p>See how the /merged directory holds the content of both upper and lower directory, where “upper wins” if there are files with similar names:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dev@debian:~/no-docker$ tail -n+1 /merged/*
==&gt; /merged/bar &lt;==
upper bar

==&gt; /merged/foo &lt;==
upper foo

==&gt; /merged/quux &lt;==
lower quux
</code></pre></div></div>

<p>Worth noting that the workdir is a “technical” directory used by overlayfs to prepare files to move them in a single atomic operation.</p>

<h1 id="conclusion">Conclusion</h1>

<p>Docker itself is not magic, the mechanisms of the kernel are the magic, and you can easily explore those mechanisms yourself. The one important part I didn’t cover here is the networking namespace.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I wrote this post trying to learn how Docker works under the hood. My learning goal was to run a Docker image without Docker.]]></summary></entry></feed>